{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# `ETraceOp`: Online Learning Operator",
   "id": "6908d888efacaf39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In `braintrace`, the Eligibility Trace Operator (`ETraceOp`) plays a central role in connecting neural populations and defining their synaptic interactions. Its primary responsibility is to compute the post-synaptic current based on the model's inputs (pre-synaptic activity) and its parameters (e.g., synaptic weights). Critically, `ETraceOp` natively supports learning mechanisms based on Eligibility Traces, which is a key process for simulating temporal credit assignment in biological neural systems. This allows the model to update connection weights based on delayed reward or error signals.\n",
    "\n",
    "The design philosophy of `ETraceOp` is to decouple the computational logic (the operator itself) from the trainable parameters (`ETraceParam`), providing significant flexibility and extensibility."
   ],
   "id": "22c7e80a152c498"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:40.303721Z",
     "start_time": "2025-07-21T15:49:39.020274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import brainevent\n",
    "import brainstate\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import braintrace"
   ],
   "id": "9ac44f0bb1d51cd9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Built-in Eligibility Trace Operators\n",
    "\n",
    "`braintrace` provides a suite of powerful, pre-configured eligibility trace operators that cater to the most common neural network modeling needs. These operators are used in conjunction with the parameter container `braintrace.ETraceParam` to form the building blocks of a neural network.\n",
    "\n",
    "The main built-in operators include:\n",
    "\n",
    "  * [`braintrace.MatMulOp`](../apis/generated/braintrace.MatMulOp.rst): Implements standard matrix multiplication, serving as the foundation for fully-connected (Dense) layers.\n",
    "  * [`braintrace.ConvOp`](../apis/generated/braintrace.ConvOp.rst): Implements convolution, supporting 1D, 2D, and 3D operations, which is core to building Convolutional Neural Networks (CNNs).\n",
    "  * [`braintrace.SpMatMulOp`](../apis/generated/braintrace.SpMatMulOp.rst): Designed for sparse connectivity, this operator implements sparse matrix multiplication. It is particularly crucial in Graph Neural Networks (GNNs) and large-scale biophysical models that require efficient representation of sparse connections.\n",
    "  * [`braintrace.ElemWiseOp`](../apis/generated/braintrace.ElemWiseOp.rst): Performs element-wise mathematical operations, often used to implement activation functions, scaling, or other custom element-by-element transformations.\n",
    "  * [`braintrace.LoraOp`](../apis/generated/braintrace.LoraOp.rst): Implements Low-Rank Adaptation, an efficient technique for fine-tuning large pre-trained models."
   ],
   "id": "de5e69fd2fd011fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `braintrace.MatMulOp`: The Matrix Multiplication Operator\n",
    "\n",
    "The [`braintrace.MatMulOp`](../apis/generated/braintrace.MatMulOp.rst) is one of the most fundamental operators, supporting matrix multiplication for scenarios like fully-connected layers.\n",
    "\n",
    "**Core Operation**:\n",
    "\n",
    "  * **Input**: A matrix $x \\in \\mathbb{R}^{B \\times D_{in}}$\n",
    "  * **Parameters**: A dictionary $w$ containing a weight matrix `weight` $\\in \\mathbb{R}^{D_{in} \\times D_{out}}$ and a bias vector `bias` $\\in \\mathbb{R}^{D\\_{out}}$\n",
    "  * **Output**: A matrix $y \\in \\mathbb{R}^{B \\times D_{out}}$\n",
    "\n",
    "**Supported Operation Types**:\n",
    "\n",
    "**1.  Standard matrix multiplication**:\n",
    "\n",
    "$$y = x \\cdot \\text{param['weight']} + \\text{param['bias']}$$\n"
   ],
   "id": "3eb9abd2ff059c76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:40.755054Z",
     "start_time": "2025-07-21T15:49:40.525869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standard matrix multiplication\n",
    "\n",
    "braintrace.ETraceParam(\n",
    "    {\n",
    "        'weight': brainstate.random.rand(4, 5),\n",
    "        'bias': brainstate.random.rand(5)\n",
    "    },\n",
    "    braintrace.MatMulOp()\n",
    ")"
   ],
   "id": "7cfcfd6102942c5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'bias': ShapedArray(float32[5]),\n",
       "    'weight': ShapedArray(float32[4,5])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=MatMulOp(\n",
       "    is_diagonal=False,\n",
       "    weight_mask=None,\n",
       "    weight_fn=<function MatMulOp.<lambda> at 0x000002A178B83B00>,\n",
       "    apply_weight_fn_before_mask=False\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**2.  Masked operation**: The `weight_mask` parameter can be used to implement sparse connections, where only weights corresponding to `True` in the mask are active.\n",
    "\n",
    "$$y = x \\cdot (\\text{param['weight']} \\odot \\text{mask}) + \\text{param['bias']}$$\n"
   ],
   "id": "dae51d24729c9e99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:40.784231Z",
     "start_time": "2025-07-21T15:49:40.764334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Matrix multiplication with a mask to implement sparse connectivity\n",
    "\n",
    "braintrace.ETraceParam(\n",
    "    {\n",
    "        'weight': brainstate.random.rand(4, 5),\n",
    "        'bias': brainstate.random.rand(5)\n",
    "    },\n",
    "    braintrace.MatMulOp(\n",
    "        weight_mask=brainstate.random.rand(4, 5) > 0.5\n",
    "    )\n",
    ")"
   ],
   "id": "c241d3ebef29e296",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'bias': ShapedArray(float32[5]),\n",
       "    'weight': ShapedArray(float32[4,5])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=MatMulOp(\n",
       "    is_diagonal=False,\n",
       "    weight_mask=Array([[ True, False, False, False,  True],\n",
       "           [False,  True,  True,  True, False],\n",
       "           [ True, False,  True,  True, False],\n",
       "           [ True, False,  True, False, False]], dtype=bool),\n",
       "    weight_fn=<function MatMulOp.<lambda> at 0x000002A178B83B00>,\n",
       "    apply_weight_fn_before_mask=False\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**3.  Weight function**: The `weight_fn` parameter applies a function to the weight matrix before multiplication. For instance, using `jnp.abs` can enforce Dale's Law by ensuring all synaptic weights are positive (excitatory).\n",
    "\n",
    "$$y = x \\cdot f(\\text{param['weight']}) + \\text{param['bias']}$$\n"
   ],
   "id": "9c88b41947814f5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:40.798923Z",
     "start_time": "2025-07-21T15:49:40.793521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply a function to the weights\n",
    "\n",
    "braintrace.ETraceParam(\n",
    "    {\n",
    "        'weight': brainstate.random.rand(4, 5),\n",
    "        'bias': brainstate.random.rand(5)\n",
    "    },\n",
    "    braintrace.MatMulOp(\n",
    "        weight_fn=jnp.abs   # Ensures weights are positive\n",
    "    )\n",
    ")"
   ],
   "id": "d6c4a54f029164c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'bias': ShapedArray(float32[5]),\n",
       "    'weight': ShapedArray(float32[4,5])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=MatMulOp(\n",
       "    is_diagonal=False,\n",
       "    weight_mask=None,\n",
       "    weight_fn=<PjitFunction of <function abs at 0x000002A14F860400>>,\n",
       "    apply_weight_fn_before_mask=False\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "4. **Composition of masking and weight function**：\n",
    "\n",
    "$$y = x \\cdot f(\\text{param['weight']} \\odot \\text{mask}) + \\text{param['bias']}$$"
   ],
   "id": "ca69e31df3334a3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:40.825631Z",
     "start_time": "2025-07-21T15:49:40.819632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 同时使用掩码和权重函数\n",
    "braintrace.ETraceParam(\n",
    "    {\n",
    "        'weight': brainstate.random.rand(4, 5),\n",
    "        'bias': brainstate.random.rand(5)\n",
    "    },\n",
    "    braintrace.MatMulOp(\n",
    "        weight_fn=jnp.abs,\n",
    "        weight_mask=brainstate.random.rand(4, 5) > 0.5\n",
    "    )\n",
    ")"
   ],
   "id": "9e951a4a5f6a5d1d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'bias': ShapedArray(float32[5]),\n",
       "    'weight': ShapedArray(float32[4,5])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=MatMulOp(\n",
       "    is_diagonal=False,\n",
       "    weight_mask=Array([[False, False, False, False,  True],\n",
       "           [ True,  True,  True,  True,  True],\n",
       "           [False, False, False, False,  True],\n",
       "           [ True,  True,  True,  True,  True]], dtype=bool),\n",
       "    weight_fn=<PjitFunction of <function abs at 0x000002A14F860400>>,\n",
       "    apply_weight_fn_before_mask=False\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `braintrace.ConvOp`: The Convolution Operator\n",
    "\n",
    "The [`braintrace.ConvOp`](../apis/generated/braintrace.ConvOp.rst) provides general-purpose convolution operations suitable for models like CNNs.\n",
    "\n",
    "**Dimensionality Support**:\n",
    "A key feature of `ConvOp` is its ability to adapt to different dimensions. By specifying the `xinfo` parameter (a `jax.ShapeDtypeStruct` object), it can automatically infer and execute 1D, 2D, or 3D convolutions:\n",
    "\n",
    "  * **1D Convolution**: For input shape `(length, channels)`, e.g., `xinfo=jax.ShapeDtypeStruct((32, 3), ...)`.\n",
    "  * **2D Convolution**: For input shape `(height, width, channels)`, e.g., `xinfo=jax.ShapeDtypeStruct((32, 32, 3), ...)`.\n",
    "  * **3D Convolution**: For input shape `(depth, height, width, channels)`, e.g., `xinfo=jax.ShapeDtypeStruct((32, 32, 32, 3), ...)`.\n",
    "\n",
    "**Supported Operation Types** (where $\\star$ denotes convolution):\n",
    "\n",
    "**1.  Standard convolution**:\n",
    "\n",
    "$$y = x \\star \\text{param['weight']} + \\text{param['bias']}$$\n",
    "\n",
    "where $\\star$ is the convolution operation."
   ],
   "id": "910f02a78e94927a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:40.921875Z",
     "start_time": "2025-07-21T15:49:40.848393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example of a 2D convolution\n",
    "braintrace.ETraceParam(\n",
    "    {\n",
    "        'weight': brainstate.random.rand(3, 3),\n",
    "        'bias': jnp.zeros(16)\n",
    "    },\n",
    "    braintrace.ConvOp(\n",
    "        xinfo=jax.ShapeDtypeStruct((32, 3, 3), jnp.float32),  # (height, width, channels)\n",
    "        window_strides=[1, 1],\n",
    "        padding='SAME',\n",
    "    )\n",
    ")"
   ],
   "id": "b0e2e11be2ed70e0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'bias': ShapedArray(float32[16]),\n",
       "    'weight': ShapedArray(float32[3,3])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=ConvOp(\n",
       "    is_diagonal=False,\n",
       "    window_strides=[\n",
       "      1,\n",
       "      1\n",
       "    ],\n",
       "    padding=SAME,\n",
       "    lhs_dilation=None,\n",
       "    rhs_dilation=None,\n",
       "    feature_group_count=1,\n",
       "    batch_group_count=1,\n",
       "    dimension_numbers=None,\n",
       "    weight_mask=None,\n",
       "    weight_fn=<function ConvOp.<lambda> at 0x000002A178B83EC0>,\n",
       "    xinfo=ShapeDtypeStruct(shape=(32, 3, 3), dtype=float32)\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Like `MatMulOp`, `ConvOp` also supports `weight_mask` and `weight_fn` for flexible and complex convolution definitions.",
   "id": "af0f15fb80c053f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**2. Masking operation**：\n",
    "\n",
    "$$y = x \\star  (\\mathrm{param['weight']} * \\mathrm{mask}) + \\mathrm{param['bias']}$$\n"
   ],
   "id": "5360541335128b26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:40.949611Z",
     "start_time": "2025-07-21T15:49:40.929960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "braintrace.ETraceParam(\n",
    "    {\n",
    "        'weight': brainstate.random.rand(3, 3),\n",
    "        'bias': jnp.zeros(16)\n",
    "    },\n",
    "    braintrace.ConvOp(\n",
    "        xinfo=jax.ShapeDtypeStruct((32, 3, 3), jnp.float32),\n",
    "        window_strides=[1, 1],\n",
    "        padding='SAME',\n",
    "        weight_mask=brainstate.random.rand(3, 3) > 0.5\n",
    "    )\n",
    ")"
   ],
   "id": "f89d525bafd429d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'bias': ShapedArray(float32[16]),\n",
       "    'weight': ShapedArray(float32[3,3])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=ConvOp(\n",
       "    is_diagonal=False,\n",
       "    window_strides=[\n",
       "      1,\n",
       "      1\n",
       "    ],\n",
       "    padding=SAME,\n",
       "    lhs_dilation=None,\n",
       "    rhs_dilation=None,\n",
       "    feature_group_count=1,\n",
       "    batch_group_count=1,\n",
       "    dimension_numbers=None,\n",
       "    weight_mask=Array([[ True, False,  True],\n",
       "           [False,  True,  True],\n",
       "           [False, False,  True]], dtype=bool),\n",
       "    weight_fn=<function ConvOp.<lambda> at 0x000002A178B83EC0>,\n",
       "    xinfo=ShapeDtypeStruct(shape=(32, 3, 3), dtype=float32)\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**3. Weight function**：\n",
    "\n",
    "$$y = x \\star  f(\\mathrm{param['weight']}) + \\mathrm{param['bias']}$$"
   ],
   "id": "a5ebcff7e320c154"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:40.965090Z",
     "start_time": "2025-07-21T15:49:40.960074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 以2D卷积为例\n",
    "braintrace.ETraceParam(\n",
    "    {\n",
    "        'weight': brainstate.random.rand(3, 3),\n",
    "        'bias': jnp.zeros(16)\n",
    "    },\n",
    "    braintrace.ConvOp(\n",
    "        xinfo=jax.ShapeDtypeStruct((32, 3, 3), jnp.float32),\n",
    "        window_strides=[1, 1],\n",
    "        padding='SAME',\n",
    "        weight_fn=jnp.abs\n",
    "    )\n",
    ")"
   ],
   "id": "f5397ebb2d95562e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'bias': ShapedArray(float32[16]),\n",
       "    'weight': ShapedArray(float32[3,3])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=ConvOp(\n",
       "    is_diagonal=False,\n",
       "    window_strides=[\n",
       "      1,\n",
       "      1\n",
       "    ],\n",
       "    padding=SAME,\n",
       "    lhs_dilation=None,\n",
       "    rhs_dilation=None,\n",
       "    feature_group_count=1,\n",
       "    batch_group_count=1,\n",
       "    dimension_numbers=None,\n",
       "    weight_mask=None,\n",
       "    weight_fn=<PjitFunction of <function abs at 0x000002A14F860400>>,\n",
       "    xinfo=ShapeDtypeStruct(shape=(32, 3, 3), dtype=float32)\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**4. Weight function + masking**：\n",
    "\n",
    "$$y = x \\star  f(\\mathrm{param['weight']} * \\mathrm{mask}) + \\mathrm{param['bias']}$$"
   ],
   "id": "6452a85597add8c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:40.986995Z",
     "start_time": "2025-07-21T15:49:40.979745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 以2D卷积为例\n",
    "braintrace.ETraceParam(\n",
    "    {\n",
    "        'weight': brainstate.random.rand(3, 3),\n",
    "        'bias': jnp.zeros(16)\n",
    "    },\n",
    "    braintrace.ConvOp(\n",
    "        xinfo=jax.ShapeDtypeStruct((32, 3, 3), jnp.float32),\n",
    "        window_strides=(1, 1),\n",
    "        padding='SAME',\n",
    "        weight_mask=brainstate.random.rand(3, 3) > 0.5,\n",
    "        weight_fn=jnp.abs,\n",
    "    )\n",
    ")"
   ],
   "id": "b193345580606f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'bias': ShapedArray(float32[16]),\n",
       "    'weight': ShapedArray(float32[3,3])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=ConvOp(\n",
       "    is_diagonal=False,\n",
       "    window_strides=(1, 1),\n",
       "    padding=SAME,\n",
       "    lhs_dilation=None,\n",
       "    rhs_dilation=None,\n",
       "    feature_group_count=1,\n",
       "    batch_group_count=1,\n",
       "    dimension_numbers=None,\n",
       "    weight_mask=Array([[ True, False, False],\n",
       "           [ True, False,  True],\n",
       "           [False, False, False]], dtype=bool),\n",
       "    weight_fn=<PjitFunction of <function abs at 0x000002A14F860400>>,\n",
       "    xinfo=ShapeDtypeStruct(shape=(32, 3, 3), dtype=float32)\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `braintrace.SpMatMulOp`: The Sparse Matrix Multiplication Operator\n",
    "\n",
    "The [`braintrace.SpMatMulOp`](../apis/generated/braintrace.SpMatMulOp.rst) operator supports sparse matrix multiplication operations, suitable for scenarios like Graph Neural Networks (GNNs). It takes feature maps $x$ and parameters $w$ as input, and outputs the sparse matrix multiplication result $y$.\n",
    "\n",
    "`braintrace.SpMatMulOp` performs similar operations to `braintrace.MatMulOp` for matrix multiplication:\n",
    "\n",
    "$$y = x @ \\text{param['weight']} + \\text{param['bias']}$$\n",
    "\n",
    "However, in this case, `param['weight']` is a sparse matrix, typically implemented using sparse matrices from [``brainevent``](https://brainevent.readthedocs.io/), which maintains computational efficiency while significantly reducing memory consumption. These include:\n",
    "\n",
    "- ``brainevent.CSR``: Compressed Sparse Row matrix.\n",
    "- ``brainevent.CSC``: Compressed Sparse Column matrix.\n",
    "- ``brainevent.COO``: Coordinate Format sparse matrix.\n",
    "\n",
    "`braintrace.SpMatMulOp` supports the following operations:\n",
    "\n",
    "**1. Standard matrix multiplication**:\n",
    "\n",
    "$$y = x @ \\text{param['weight']} + \\text{param['bias']}$$\n",
    "\n",
    "\n"
   ],
   "id": "20fd18e264c39e7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:41.219381Z",
     "start_time": "2025-07-21T15:49:41.005451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = jnp.where(\n",
    "    brainstate.random.rand(100, 100) < 0.2,\n",
    "    brainstate.random.rand(100, 100),\n",
    "    0.\n",
    ")\n",
    "csr = brainevent.CSR.fromdense(data)"
   ],
   "id": "3e4af69c29669154",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:41.297203Z",
     "start_time": "2025-07-21T15:49:41.236623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "braintrace.ETraceParam(\n",
    "    {'weight': brainstate.random.rand(100)},\n",
    "    braintrace.SpMatMulOp(csr)\n",
    ")"
   ],
   "id": "39d0558b3f089277",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'weight': ShapedArray(float32[100])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=SpMatMulOp(\n",
       "    is_diagonal=False,\n",
       "    sparse_mat=CSR(float32[100, 100], nse=1924),\n",
       "    weight_fn=<function SpMatMulOp.<lambda> at 0x000002A178BA42C0>\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**2. Weight function**:\n",
    "\n",
    "$$y = x @ f(\\text{param['weight']}) + \\text{param['bias']}$$\n"
   ],
   "id": "d63a39fe44781b90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:41.319874Z",
     "start_time": "2025-07-21T15:49:41.314906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "braintrace.ETraceParam(\n",
    "    {'weight': brainstate.random.rand(100)},\n",
    "    braintrace.SpMatMulOp(csr, weight_fn=jnp.abs)\n",
    ")"
   ],
   "id": "b596da0930657089",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value={\n",
       "    'weight': ShapedArray(float32[100])\n",
       "  },\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=SpMatMulOp(\n",
       "    is_diagonal=False,\n",
       "    sparse_mat=CSR(float32[100, 100], nse=1924),\n",
       "    weight_fn=<PjitFunction of <function abs at 0x000002A14F860400>>\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### `braintrace.ElemWiseOp`: Element-wise Operation Operator\n",
    "\n",
    "[`braintrace.ElemWiseOp`](../apis/generated/braintrace.ElemWiseOp.rst) provides a concise way to apply element-wise function transformations to parameters. It doesn't directly process pre-synaptic input $x$, but operates directly on its own parameters $w$.\n",
    "\n",
    "**Core Operation**:\n",
    "\n",
    "$$y = f(w)$$\n",
    "\n",
    "This can be used to create learnable activation function parameters, neuron thresholds, time constants, etc.\n",
    "\n",
    "Here are some typical examples of element-wise operation operators:\n"
   ],
   "id": "fcc1bf27989471b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:41.434583Z",
     "start_time": "2025-07-21T15:49:41.335002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "braintrace.ETraceParam(\n",
    "    brainstate.random.rand(4),\n",
    "    braintrace.ElemWiseOp(jnp.abs)  # Absolute value operation\n",
    ")"
   ],
   "id": "81c5e77aa9ed9030",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value=ShapedArray(float32[4]),\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=ElemWiseOp(\n",
       "    fn=<PjitFunction of <function abs at 0x000002A14F860400>>,\n",
       "    is_diagonal=True\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:41.451552Z",
     "start_time": "2025-07-21T15:49:41.445276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "braintrace.ETraceParam(\n",
    "    brainstate.random.rand(4),\n",
    "    braintrace.ElemWiseOp(jnp.exp)  # Exponential operation\n",
    ")"
   ],
   "id": "4bc5020e648a3bb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value=ShapedArray(float32[4]),\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=ElemWiseOp(\n",
       "    fn=<PjitFunction of <function exp at 0x000002A14F8054E0>>,\n",
       "    is_diagonal=True\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:41.470190Z",
     "start_time": "2025-07-21T15:49:41.465333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Using custom lambda function\n",
    "\n",
    "braintrace.ETraceParam(\n",
    "    brainstate.random.rand(4),\n",
    "    braintrace.ElemWiseOp(lambda x: x ** 2 + 1.)  # Custom function\n",
    ")"
   ],
   "id": "c8c3c04eabe07a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ETraceParam(\n",
       "  value=ShapedArray(float32[4]),\n",
       "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
       "  op=ElemWiseOp(\n",
       "    fn=<function <lambda> at 0x000002A17672A340>,\n",
       "    is_diagonal=True\n",
       "  ),\n",
       "  is_etrace=True\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Custom Eligibility Trace Operators\n",
    "\n",
    "Although `braintrace` provides a comprehensive suite of built-in operators, research and applications often require exploration of novel neural network layers or synaptic plasticity rules. For this purpose, `braintrace` allows users to easily create custom operators by inheriting from the `braintrace.ETraceOp` base class.\n",
    "\n",
    "Customizing an operator involves understanding and implementing two core methods: `xw_to_y` and `yw_to_w`.\n",
    "\n",
    "1. **`xw_to_y(self, x, w)`: Define Forward Propagation**\n",
    "\n",
    "   * **Purpose**: This method defines the core computational logic of the operator, i.e., how to compute the post-synaptic output `y` based on pre-synaptic input `x` and operator parameters `w`. It is functionally equivalent to the `forward` method of layers in standard deep learning frameworks.\n",
    "   * **Mathematical representation**: $y = f(x, w)$.\n",
    "   * **Parameters**:\n",
    "     * `x`: Pre-synaptic neural activity (e.g., spikes, firing rates, or feature vectors).\n",
    "     * `w`: A dictionary containing all learnable parameters of this operator (e.g., `{'weight': ..., 'bias': ...}`).\n",
    "\n",
    "![](../_static/etraceop-xw2y.png)\n",
    "\n",
    "2. **`yw_to_w(self, y, w)`: Define Gradient/Trace Propagation**\n",
    "\n",
    "   * **Purpose**: This method is the core of the eligibility trace learning mechanism. It defines how \"learning signals\" from post-synaptic neurons (typically error gradients) \"flow back\" and influence the eligibility trace of each parameter. It answers the question: \"How much does a change in output `y` affect parameter `w`?\"\n",
    "   * **Mathematical representation**: $w_{new} = g(y_{grad}, w)$. Here, $y_{grad}$ is an abstract \"learning signal,\" and $w_{new}$ represents the update direction of parameters or their eligibility trace.\n",
    "   * **Application scenario**: The computation result of this method will be directly used to update the eligibility trace $\\boldsymbol{\\epsilon}^{t}$. The final weight update $\\Delta w$ will be the product of the learning signal (such as reward prediction error) and the eligibility trace, i.e., $\\Delta w \\propto \\text{LearningSignal} \\cdot \\boldsymbol{\\epsilon}^{t}$.\n",
    "   * **Parameters**:\n",
    "     * `y`: A vector representing learning signal or gradient, with dimensions matching the output dimensions of `xw_to_y`.\n",
    "     * `w`: Current parameter dictionary.\n",
    "\n",
    "![](../_static/etraceop-yw2w.png)\n",
    "\n",
    "\n",
    "### Example: Building `CustomizedMatMul` from Scratch\n",
    "\n",
    "Let's demonstrate how to customize an operator that has the same functionality as `MatMulOp` through a concrete example.\n"
   ],
   "id": "fb0421251a788ffa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:41.503526Z",
     "start_time": "2025-07-21T15:49:41.499295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomizedMatMul(braintrace.ETraceOp):\n",
    "    \"\"\"\n",
    "    A custom matrix multiplication eligibility trace operator.\n",
    "    It implements the computation y = x @ w['weight'] + w['bias'].\n",
    "    \"\"\"\n",
    "    def xw_to_y(self, x, w: dict):\n",
    "        \"\"\"\n",
    "        Forward propagation: compute y = x @ weight + bias\n",
    "        \"\"\"\n",
    "        return jnp.dot(x, w['weight']) + w['bias']\n",
    "\n",
    "    def yw_to_w(self, y, w: dict):\n",
    "        \"\"\"\n",
    "        Parameter update (for eligibility trace): compute how learning signals affect weights and biases.\n",
    "        This is similar to computing gradients dL/dw = dL/dy * dy/dw.\n",
    "        \"\"\"\n",
    "\n",
    "        # For weight w['weight'], its gradient is the outer product of input x and output gradient y.\n",
    "        # Here, we expand y's dimensions from (B, D_out) to (B, 1, D_out),\n",
    "        # and x's dimensions from (B, D_in) to (B, D_in, 1),\n",
    "        # thus implementing batch outer product computation through broadcast multiplication (x[..., None] * y[:, None, :]).\n",
    "        # For simplification, we represent this dependency relationship in a more abstract way.\n",
    "        y_expanded = jnp.expand_dims(y, axis=-2) # Shape becomes (..., 1, D_out)\n",
    "        return {\n",
    "            'weight': y_expanded * w['weight'], # Example update rule\n",
    "            'bias': y * w['bias'] # Example update rule\n",
    "        }"
   ],
   "id": "cadbd5b6530562dc",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Code Analysis**:\n",
    "\n",
    "* In `xw_to_y`, we implement the logic of standard matrix multiplication plus bias, which is very intuitive.\n",
    "* In `yw_to_w`, we define the update rules. The keys and value shapes of the returned dictionary must exactly match the original parameters `w`. `jnp.expand_dims` is used here to adjust the dimensions of `y` to ensure the broadcast mechanism can correctly apply the influence of `y` to each element of `w['weight']`.\n",
    "\n",
    "### Using Custom Operators\n",
    "\n",
    "Once defined, `CustomizedMatMul` can be used like any built-in operator, combined with `ETraceParam`, and seamlessly integrated into `braintrace`'s computational graph.\n"
   ],
   "id": "3dc38faec8488857"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-21T15:49:41.595091Z",
     "start_time": "2025-07-21T15:49:41.517928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Instantiate custom operator\n",
    "my_op = CustomizedMatMul()\n",
    "\n",
    "# 2. Use ETraceParam to associate operator with specific parameters\n",
    "param = braintrace.ETraceParam(\n",
    "    {\n",
    "        'weight': brainstate.random.rand(4, 5),  # D_in=4, D_out=5\n",
    "        'bias': brainstate.random.rand(5)\n",
    "    },\n",
    "    my_op # Pass custom operator instance\n",
    ")\n",
    "\n",
    "# 3. Use in model (simulation)\n",
    "# Create some mock input data\n",
    "dummy_input = brainstate.random.rand(1, 4) # Batch=1, D_in=4\n",
    "\n",
    "# braintrace's runner will automatically call op.xw_to_y(dummy_input, param.value)\n",
    "# We can manually call to verify\n",
    "output = my_op.xw_to_y(dummy_input, param.value)\n",
    "\n",
    "print(\"Custom operator instantiation:\")\n",
    "print(param)\n",
    "print(\"\\nForward computation output:\")\n",
    "print(output)\n",
    "print(\"Output shape:\", output.shape)"
   ],
   "id": "888772f24e5948f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom operator instantiation:\n",
      "ETraceParam(\n",
      "  value={\n",
      "    'bias': ShapedArray(float32[5]),\n",
      "    'weight': ShapedArray(float32[4,5])\n",
      "  },\n",
      "  gradient=<ETraceGrad.adaptive: 'adaptive'>,\n",
      "  op=CustomizedMatMul(\n",
      "    is_diagonal=False\n",
      "  ),\n",
      "  is_etrace=True\n",
      ")\n",
      "\n",
      "Forward computation output:\n",
      "[[1.8759773 1.6249228 1.8983953 1.4766655 1.8770288]]\n",
      "Output shape: (1, 5)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Through this approach, you can build highly customized components for novel neuron models, complex synaptic plasticity rules, or any scenario requiring differentiable parameters and custom computational logic.",
   "id": "800ac8408a109b51"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
